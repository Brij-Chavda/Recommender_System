# -*- coding: utf-8 -*-
"""Untitled23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UcOiDAPytODHatiI8Vl5sXVFcbnJeHXm
"""

!pip install scrapbook
!pip install recommenders[examples,gpu]

import sys
import os
import cornac
import papermill as pm
import scrapbook as sb
import pandas as pd
from recommenders.datasets import movielens
from recommenders.datasets.python_splitters import python_random_split
from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k
from recommenders.models.cornac.cornac_utils import predict_ranking
from recommenders.utils.timer import Timer
from recommenders.utils.constants import SEED

print("System version: {}".format(sys.version))
print("Cornac version: {}".format(cornac.__version__))

from recommenders.models.cornac.cornac_utils import predict

# Select MovieLens data size: 100k, 1m, 10m, or 20m
MOVIELENS_DATA_SIZE = '100k'

# top k items to recommend
TOP_K = 10

# Model parameters
NUM_FACTORS = 200
NUM_EPOCHS = 100

data = movielens.load_pandas_df(
    size=MOVIELENS_DATA_SIZE,
    header=["userID", "itemID", "rating"]
)

data.head()

train, test = python_random_split(data, 0.75)

train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)

print('Number of users: {}'.format(train_set.num_users))
print('Number of items: {}'.format(train_set.num_items))



for i in range(50, 500, 50):
  bpr = cornac.models.BPR(
    k=i,
    max_iter=NUM_EPOCHS,
    learning_rate=0.01,
    lambda_reg=0.001,
    verbose=True,
    seed=SEED
  )
  with Timer() as t:
    bpr.fit(train_set)
  print("Took {} seconds for training.".format(t))
  with Timer() as t:
    all_predictions = predict_ranking(bpr, train, usercol='userID', itemcol='itemID', remove_seen=True)
  print("Took {} seconds for prediction.".format(t))
  k = 10
  eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=k)
  eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=k)
  eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=k)
  eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=k)
  print(i)
  print("MAP:\t%f" % eval_map,
        "NDCG:\t%f" % eval_ndcg,
        "Precision@K:\t%f" % eval_precision,
        "Recall@K:\t%f" % eval_recall, sep='\n')
  print('\n')
  print('\n')

import pandas as pd
df = pd.read_csv('/content/_6ccdb1ada9b0f3e110e90d1eb0fea594_daily_weather.csv')

print(df.head())

print(df['number'].count())

print(len(df['rain_accumulation_9am']))

print((df[df['max_wind_speed_9am'] == max(df['max_wind_speed_9am'])]))